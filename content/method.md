## Method
{:#method}
The RL-based optimizer builds <span class="rephrase" data-author="RV">a join plan</span> by greedily adding joins <span class="rephrase" data-author="RV">to the join plan</span> that minimize the estimated query execution time.
<span class="comment" data-author="RV">Needs slight rephrasing: unclear where the initial join plan that you're adding joins to comes from</span>
We estimate the execution time of the query using a neural network, which we train to minimize the <span class="rephrase" data-author="RV">MSE</span> between predicted and actual query execution time. The neural network is fed a numerical representation of the current join plan as an input. \\
**Join plan representation** Like in <ins class="comment" data-author="RV">the query processor (or whatever it is)</ins> [RTOS](cite:cites yu2020reinforcement), we represent join plans as a tree that we build from the bottom up. Each leaf node represents the result set of a triple pattern, and internal nodes represent join result sets. We represent result sets using their cardinality, the presence and location of variables, named nodes and literals, and a vector representation of the predicate.
We learn the predicate representation vectors by applying <ins class="comment" data-author="RV">the algorithm (or whatever it is)</ins> [RDF2Vec](cite:cites ristoski2016rdf2vec) to the input RDF graph. The predicate vectors contain semantic information relating to the encoded predicate. 
<span class="comment" data-author="RV">If you replace any acronym or name by <q>smurf</q>, the paper should still make sense; that's why I'm adding those modifiers before</span>
We obtain the representations for intermediate joins by applying an N-ary Tree-LSTM <span class="comment" data-author="RV">the reader doesn't know what that is at this point</span> on the result sets representations involved in the join. Finally, at the (partial) join plan root node, we apply a Child-Sum Tree-LSTM [operation](cite:cites tai2015improved) to all unjoined result sets to obtain the join plan representation.\\
**Data efficiency & SPARQL specific adjustments** Data generation using query execution is slow; we account for this by applying two data efficiency techniques. First, we include a _time-out_ that is set according to existing optimizers. We effectively truncate our optimization variable, while ensuring the optimal query plan will not reach the time-out. Second, we use [_experience replay_](cite:cites lin1992self) to store previous (expensive) query executions and reuse them for training. \\
Relational RL-based optimization approaches use [_one-hot encoding_](cite:cites muller2016introduction) of database attributes to create feature vectors. However, the Wikidata graph has over a 100 million unique entries. <span class="comment" data-author="RV">Unclear where Wikidata comes from; is this the one we're using for testing? Thought it was just an example in the intro.</span> <span class="rephrase" data-author="RV">This</span> would create unwieldy vectors, thus we do not use one-hot encoding in our approach. <span class="rephrase" data-author="RV">This</span> complicates creating informative features but improves scalability. \\
<span class="comment" data-author="RV">Unclear what both <q>this</q> references are to</span>
**Open Challenges** We do not encode the connections between triple patterns; <span class="comment" data-author="RV">why?</span> these encodings should <span class="comment" data-author="RV">why?</span> reflect the different types of connections between triple patterns, like object-object, subject-subject, object-subject, and subject-object. Furthermore, our approach can only optimize basic graph patterns; in future work, this approach can be extended to more complex SPARQL query operations.
